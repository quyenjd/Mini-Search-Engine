Filippo Menczer is an American and Italian professor of informatics and computer science who is the former director at the Center for Complex Networks and Systems Research,[1] a research unit of the Indiana University School of Informatics, Computing, and Engineering. He holds courtesy appointments in Cognitive Science and Physics, is a founding member and advisory council member of the IU Network Science Institute,[2] a senior research fellow of the Kinsey Institute, and a fellow of the Center for Computer-Mediated Communication,[3] and a former fellow of the Institute for Scientific Interchange in Turin, Italy. In 2013 he was named a Distinguished Scientist of the ACM.[4]

Menczer holds a Laurea in physics from the Sapienza University of Rome and a PhD in computer science and cognitive science from the University of California, San Diego. He used to be an assistant professor of management sciences at the University of Iowa, and a fellow-at-large of the Santa Fe Institute. At Indiana University Bloomington since 2003, he served as division chair in the Indiana University School of Informatics and Computing in 2009-2011. Menczer has been the recipient of Fulbright, Rotary Foundation, and NATO fellowships, and a Career Award from the National Science Foundation. He holds editorial positions for the journals EPJ Data Science,[5] Network Science,[6] and PeerJ Computer Science.[7] He has served as program or track chair for various conferences including the International World Wide Web Conference and the International ACM Conference on Hypertext and Social Media.[8] He was general chair of the ACM Web Science 2014 Conference[9] and general co-chair of the NetSci 2017 Conference.[10]

Menczer's research focuses on Web science, social networks, social media, social computation, Web mining, data science, distributed and intelligent Web applications, and modeling of complex information networks. He introduced the idea of topical and adaptive Web crawlers, a specialized and intelligent type of Web crawler.[11][12]

Menczer is also known for his work on social phishing,[13][14] a type of phishing attacks that leverage friendship information from social networks, yielding over 70% success rate in experiments (with Markus Jakobsson); semantic similarity measures for information and social networks;[15][16][17][18] models of complex information and social networks (with Alessandro Vespignani and others);[19][20][21][22] search engine censorship;[23][24] and search engine bias.[25][26]

The group led by Menczer has analyzed and modeled how memes, information, and misinformation spread through social media in domains such as the Occupy movement,[27][28] the Gezi Park protests,[29] and political elections.[30][31] Data and tools from Menczer's lab have aided in finding the roots of the Pizzagate conspiracy theory[32] and the disinformation campaign targeting the White Helmets,[33] and in taking down voter-suppression bots on Twitter.[34]

Menczer and colleagues have advanced the understanding of information virality, and in particular the prediction of what memes will go viral based on the structure of early diffusion networks[35][36] and how competition for finite attention helps explain virality patterns.[37][38] In a 2018 paper in Nature Human Behaviour, Menczer and coauthors used a model to show that when agents in a social networks share information under conditions of high information load and/or low attention, the correlation between quality and popularity of information in the system decreases.[39] An erroneous analysis in the paper suggested that this effect alone would be sufficient to explain why fake news are as likely to go viral as legitimate news on Facebook. When the authors discovered the error, they retracted the paper.[40]

Following influential publications on the detection of astroturfing[41][42][43][44][45] and social bots,[46][47] Menczer and his team have studied the complex interplay between cognitive, social, and algorithmic factors that contribute to the vulnerability of social media platforms and people to manipulation,[48][49][50][51] and focused on developing tools to counter such abuse.[52][53] Their bot detection tool, Botometer, was used to assess the prevalence of social bots[54][55] and their sharing activity.[56] Their tool to visualize the spread of low-credibility content, Hoaxy,[57][58][59][60] was used in conjunction with Botometer to reveal the key role played by social bots in spreading low-credibility content during the 2016 United States presidential election.[61][62][63][64][65]

